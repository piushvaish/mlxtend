{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bootstrap_point632_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An implementation of the .632 bootstrap to evaluate supervised learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `from mlxtend.evaluate import bootstrap_point632_score`    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally, the bootstrap method aims to determine the statistical properties of an estimator when the underlying distribution was unknown and additional samples are not available. Now, in order to exploit this method for the evaluation of predictive models, such as hypotheses for classification and regression, we may prefer a slightly different approach to bootstrapping using the so-called Out-Of-Bag (OOB) or Leave-One-Out Bootstrap (LOOB) technique. Here, we use out-of-bag samples as test sets for evaluation instead of evaluating the model on the training data. Out-of-bag samples are the unique sets of instances that are not used for model fitting as shown in the figure below [1].\n",
    "\n",
    "![](BootstrapOutOfBag_files/bootstrap_concept.png)\n",
    "\n",
    "\n",
    "The figure above illustrates how three random bootstrap samples drawn from an exemplary ten-sample dataset ($X_1,X_2, ..., X_{10}$) and their out-of-bag sample for testing may look like. In practice, Bradley Efron and Robert Tibshirani recommend drawing 50 to 200 bootstrap samples as being sufficient for reliable estimates [2].\n",
    "\n",
    "\n",
    "### .632 Bootstrap\n",
    "\n",
    "\n",
    "In 1983, Bradley Efron described the *.632 Estimate*, a further improvement to address the pessimistic bias of the bootstrap cross-validation approach described above [3]. The pessimistic bias in the \"classic\" bootstrap method can be attributed to the fact that the bootstrap samples only contain approximately 63.2% of the unique samples from the original dataset. For instance, we can compute the probability that a given sample from a dataset of size *n* is *not* drawn as a bootstrap sample as\n",
    "\n",
    "$$P (\\text{not chosen}) =  \\bigg(1 - \\frac{1}{n}\\bigg)^n,$$\n",
    "\n",
    "which is asymptotically equivalent to $\\frac{1}{e} \\approx 0.368$ as $n \\rightarrow \\infty.$\n",
    "\n",
    "Vice versa, we can then compute the probability that a sample *is* chosen as $P (\\text{chosen}) = 1 - \\bigg(1 - \\frac{1}{n}\\bigg)^n \\approx 0.632$ for reasonably large datasets, so that we'd select approximately $0.632 \\times n$ uniques samples as bootstrap training sets and reserve $ 0.368 \\times n $ out-of-bag samples for testing in each iteration.\n",
    "\n",
    "\n",
    "Now, to address the bias that is due to this the sampling with replacement, Bradley Efron proposed the *.632 Estimate* that we mentioned earlier, which is computed via the following equation:\n",
    "\n",
    "$$\\text{ACC}_{boot} = \\frac{1}{b} \\sum_{i=1}^b \\big(0.632 \\cdot \\text{ACC}_{h, i} + 0.368 \\cdot \\text{ACC}_{r, i}\\big), $$\n",
    "\n",
    "where $\\text{ACC}_{r, i}$ is the resubstitution accuracy, and $\\text{ACC}_{h, i}$ is the accuracy on the out-of-bag sample.\n",
    "\n",
    "### .632+ Bootstrap\n",
    "\n",
    "Now, while the *.632 Boostrap* attempts to address the pessimistic bias of the estimate, an optimistic bias may occur with models that tend to overfit so that Bradley Efron and Robert Tibshirani proposed the *The .632+ Bootstrap Method* (Efron and Tibshirani, 1997). Instead of using a fixed \"weight\" $\\omega = 0.632$ in\n",
    "\n",
    "$$\n",
    "ACC_{\\text{boot}} = \\frac{1}{b} \\sum_{i=1}^b \\big(\\omega \\cdot \\text{ACC}_{h, i} + (1-\\omega) \\cdot \\text{ACC}_{r, i} \\big), $$\n",
    "\n",
    "we compute the weight $\\gamma$ as\n",
    "\n",
    "$$\\omega = \\frac{0.632}{1 - 0.368 \\times R},$$\n",
    "\n",
    "where *R* is the *relative overfitting rate*\n",
    "\n",
    "$$R = \\frac{(-1) \\times (\\text{ACC}_{h, i} - \\text{ACC}_{r, i})}{\\gamma - (1 -\\text{ACC}_{h, i})}.$$\n",
    "\n",
    "(Since we are plugging $\\omega$ into the equation for computing $$ACC_{boot}$$ that we defined above, $$\\text{ACC}_{h, i}$$ and $\\text{ACC}_{r, i}$ still refer to the resubstitution and out-of-bag accuracy estimates in the *i*th bootstrap round, respectively.)\n",
    "\n",
    "Further, we need to determine the *no-information rate* $\\gamma$ in order to compute *R*. For instance, we can compute $\\gamma$ by fitting a model to a dataset that contains all possible combinations between samples $x_{i'}$ and target class labels $y_{i}$ &mdash; we pretend that the observations and class labels are independent:\n",
    "\n",
    "$$\\gamma = \\frac{1}{n^2} \\sum_{i=1}^{n} \\sum_{i '=1}^{n} L(y_{i}, f(x_{i '})).$$\n",
    "\n",
    "Alternatively, we can estimate the no-information rate $\\gamma$ as follows:\n",
    "\n",
    "$$\\gamma = \\sum_{k=1}^K p_k (1 - q_k),$$\n",
    "\n",
    "where $p_k$ is the proportion of class $k$ samples observed in the dataset, and $q_k$ is the proportion of class $k$ samples that the classifier predicts in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- [1]  https://sebastianraschka.com/blog/2016/model-evaluation-selection-part2.html\n",
    "- [2] Efron, Bradley, and Robert J. Tibshirani. An introduction to the bootstrap. CRC press, 1994. Management of Data (ACM SIGMOD '97), pages 265-276, 1997.\n",
    "[3] Efron, Bradley. 1983. “Estimating the Error Rate of a Prediction Rule: Improvement on Cross-Validation.” Journal of the American Statistical Association 78 (382): 316. doi:10.2307/2288636.\n",
    "- [4] Efron, Bradley, and Robert Tibshirani. 1997. “Improvements on Cross-Validation: The .632+ Bootstrap Method.” Journal of the American Statistical Association 92 (438): 548. doi:10.2307/2965703."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 -- Evaluating the predictive performance of a model via the classic out-of-bag Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bootstrap_point632_score` function mimics the behavior of scikit-learn's `cross_val_score, and a typically usage example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.36%\n",
      "95% Confidence interval: [88.46, 98.31]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Model accuracy\n",
    "scores = bootstrap_point632_score(tree, X, y, method='oob')\n",
    "acc = np.mean(scores)\n",
    "print('Accuracy: %.2f%%' % (100*acc))\n",
    "\n",
    "\n",
    "# Confidence interval\n",
    "lower = np.percentile(scores, 2.5)\n",
    "upper = np.percentile(scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (100*lower, 100*upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2 -- Evaluating the predictive performance of a model via the .632 Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.57%\n",
      "95% Confidence interval: [92.37, 98.95]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Model accuracy\n",
    "scores = bootstrap_point632_score(tree, X, y)\n",
    "acc = np.mean(scores)\n",
    "print('Accuracy: %.2f%%' % (100*acc))\n",
    "\n",
    "\n",
    "# Confidence interval\n",
    "lower = np.percentile(scores, 2.5)\n",
    "upper = np.percentile(scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (100*lower, 100*upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3 -- Evaluating the predictive performance of a model via the .632+ Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.28%\n",
      "95% Confidence interval: [92.10, 98.90]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Model accuracy\n",
    "scores = bootstrap_point632_score(tree, X, y, method='.632+')\n",
    "acc = np.mean(scores)\n",
    "print('Accuracy: %.2f%%' % (100*acc))\n",
    "\n",
    "\n",
    "# Confidence interval\n",
    "lower = np.percentile(scores, 2.5)\n",
    "upper = np.percentile(scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (100*lower, 100*upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## bootstrap_point632_score\n",
      "\n",
      "*bootstrap_point632_score(estimator, X, y, n_splits=200, method='.632', scoring_func=None, random_seed=None, clone_estimator=True)*\n",
      "\n",
      "Implementation of the .632 [1] and .632+ [2] bootstrap\n",
      "for supervised learning\n",
      "\n",
      "References:\n",
      "\n",
      "- [1] Efron, Bradley. 1983. “Estimating the Error Rate\n",
      "of a Prediction Rule: Improvement on Cross-Validation.”\n",
      "Journal of the American Statistical Association\n",
      "78 (382): 316. doi:10.2307/2288636.\n",
      "- [2] Efron, Bradley, and Robert Tibshirani. 1997.\n",
      "“Improvements on Cross-Validation: The .632+ Bootstrap Method.”\n",
      "Journal of the American Statistical Association\n",
      "92 (438): 548. doi:10.2307/2965703.\n",
      "\n",
      "**Parameters**\n",
      "\n",
      "- `estimator` : object\n",
      "\n",
      "    An estimator for classification or regression that\n",
      "    follows the scikit-learn API and implements \"fit\" and \"predict\"\n",
      "    methods.\n",
      "\n",
      "\n",
      "- `X` : array-like\n",
      "\n",
      "    The data to fit. Can be, for example a list, or an array at least 2d.\n",
      "\n",
      "\n",
      "- `y` : array-like, optional, default: None\n",
      "\n",
      "    The target variable to try to predict in the case of\n",
      "    supervised learning.\n",
      "\n",
      "\n",
      "- `n_splits` : int (default=200)\n",
      "\n",
      "    Number of bootstrap iterations.\n",
      "    Must be larger than 1.\n",
      "\n",
      "\n",
      "- `method` : str (default='.632')\n",
      "\n",
      "    The bootstrap method, which can be either\n",
      "    - 1) '.632' bootstrap (default)\n",
      "    - 2) '.632+' bootstrap\n",
      "    - 3) 'oob' (regular out-of-bag, no weighting)\n",
      "    for comparison studies.\n",
      "\n",
      "\n",
      "- `scoring_func` : callable,\n",
      "\n",
      "    Score function (or loss function) with signature\n",
      "``scoring_func(y, y_pred, **kwargs)``.\n",
      "    If none, uses classification accuracy if the\n",
      "\n",
      "estimator is a classifier and mean squared error\n",
      "    if the estimator is a regressor.\n",
      "\n",
      "\n",
      "- `random_seed` : int (default=None)\n",
      "\n",
      "    If int, random_seed is the seed used by\n",
      "    the random number generator.\n",
      "\n",
      "\n",
      "- `clone_estimator` : bool (default=True)\n",
      "\n",
      "    Clones the estimator if true, otherwise fits\n",
      "    the original.\n",
      "\n",
      "**Returns**\n",
      "\n",
      "- `scores` : array of float, shape=(len(list(n_splits)),)\n",
      "\n",
      "    Array of scores of the estimator for each bootstrap\n",
      "    replicate.\n",
      "\n",
      "**Examples**\n",
      "\n",
      "\n",
      "    >>> from sklearn import datasets, linear_model\n",
      "    >>> from mlxtend.evaluate import bootstrap_point632_score\n",
      "    >>> iris = datasets.load_iris()\n",
      "    >>> X = iris.data\n",
      "    >>> y = iris.target\n",
      "    >>> lr = linear_model.LogisticRegression()\n",
      "    >>> scores = bootstrap_point632_score(lr, X, y)\n",
      "    >>> acc = np.mean(scores)\n",
      "    >>> print('Accuracy:', acc)\n",
      "    0.953023146884\n",
      "    >>> lower = np.percentile(scores, 2.5)\n",
      "    >>> upper = np.percentile(scores, 97.5)\n",
      "    >>> print('95%% Confidence interval: [%.2f, %.2f]' % (lower, upper))\n",
      "    95% Confidence interval: [0.90, 0.98]\n",
      "\n",
      "For more usage examples, please see\n",
      "[http://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/](http://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../../api_modules/mlxtend.evaluate/bootstrap_point632_score.md', 'r') as f:\n",
    "    s = f.read() \n",
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
